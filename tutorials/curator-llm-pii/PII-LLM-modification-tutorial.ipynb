{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f09bf08-24a0-40a3-9a95-bea06bfa1d6f",
   "metadata": {},
   "source": [
    "## LLM-based PII Modification with NeMo Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc7ba0-3a99-4f75-b6a5-1142222212c4",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use NVIDIA's NeMo Curator library to modify text data containing Personally Identifiable Information (PII) using large language models (LLMs). We'll explore both asynchronous and synchronous approaches using `AsyncLLMPiiModifier` and `LLMPiiModifier`.\n",
    "\n",
    "PII modification with NeMo Curator provides a sophisticated approach to privacy protection while maintaining data utility. The LLM-based modifiers offer intelligent, context-aware transformations that preserve the natural flow and usefulness of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c4b86-ed75-45f0-9dfa-0837d0d36625",
   "metadata": {},
   "source": [
    "## Using Large Language Models (LLMs) for PII Modification\n",
    "Beyond rule-based systems like [Presidio](https://microsoft.github.io/presidio/) (used by `PiiModifier`), NeMo Curator also offers capabilities to leverage large language models (LLMs) for identifying and redacting PII. This approach can potentially identify a wider range of PII types or handle more nuanced cases, depending on the LLM used and the provided prompts. This requires access to an LLM endpoint compatible with the [OpenAI API standard](https://platform.openai.com/docs/api-reference/introduction), such as [NVIDIA NIM](https://developer.nvidia.com/nim) (NVIDIA Inference Microservices). NeMo Curator provides two primary modifiers for this purpose:\n",
    "\n",
    "- `AsyncLLMPiiModifier`: Performs PII detection and redaction using asynchronous calls to the LLM endpoint. This is generally more efficient for large datasets as it can handle multiple requests concurrently.\n",
    "\n",
    "- `LLMPiiModifier`: Performs PII detection and redaction using synchronous calls to the LLM endpoint. This might be simpler for smaller tasks or debugging but is less scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8235885-2edf-432f-9952-602e178066f8",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.10 or later\n",
    "- NVIDIA NeMo Curator library\n",
    "- Access to a NVIDIA Inference Microservice (NIM) endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15ebfb-5c07-493b-a14e-7fab1c7ade18",
   "metadata": {},
   "source": [
    "## Step 1: Installation and Imports\n",
    "\n",
    "First, let's install the necessary packages and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb23a35-e829-49f5-aa2b-455864c5fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NeMo Curator with all features\n",
    "# !pip install --extra-index-url https://pypi.nvidia.com nemo-curator[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fb7a2-ed1f-419b-aad5-1ad731e51938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nemo_curator.datasets import DocumentDataset\n",
    "from nemo_curator.modifiers.async_llm_pii_modifier import AsyncLLMPiiModifier\n",
    "from nemo_curator.modifiers.llm_pii_modifier import LLMPiiModifier\n",
    "from nemo_curator.modules.modify import Modify\n",
    "from nemo_curator.utils.distributed_utils import get_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f8231-9a2d-455d-8a3e-22d4287a2d11",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Dask Client (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11453916-8643-4907-b62b-48adec71c62e",
   "metadata": {},
   "source": [
    "If you're working with large datasets, you might want to initialize a Dask client. This step is optional for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463aea6-bf30-47eb-8ad6-3df16c8cbf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.40s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.59s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:00,  1.09it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.48s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.21it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.30s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.60s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.25it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.55s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Optional: Start a Dask client (recommended for larger datasets)\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85146b-a0d7-4b6f-8b1d-d155636b31ea",
   "metadata": {},
   "source": [
    "## Step 3: Create Sample Dataset\n",
    "Let's create a sample dataset containing various types of PII. This dataset will demonstrate different types of personally identifiable information that we want to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fc80ba-663c-4f6f-9268-d179d6e81cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Contact Sarah Johnson at sarah.j@company.com o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Patient ID: 12345, SSN: 123-45-6789, DOB: 01/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Send payment to Bitcoin wallet 1A1zP1eP5QGefi2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meeting with Dr. James Wilson at 123 Medical C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User @tech_jane (Jane Smith) posted from IP ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                               text\n",
       "0       1  Contact Sarah Johnson at sarah.j@company.com o...\n",
       "1       2  Patient ID: 12345, SSN: 123-45-6789, DOB: 01/1...\n",
       "2       3  Send payment to Bitcoin wallet 1A1zP1eP5QGefi2...\n",
       "3       4  Meeting with Dr. James Wilson at 123 Medical C...\n",
       "4       5  User @tech_jane (Jane Smith) posted from IP ad..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create sample data with various PII types\n",
    "data = {\n",
    "    \"doc_id\": range(1, 6),\n",
    "    \"text\": [\n",
    "        \"Contact Sarah Johnson at sarah.j@company.com or call 555-0123.\",\n",
    "        \"Patient ID: 12345, SSN: 123-45-6789, DOB: 01/15/1980\",\n",
    "        \"Send payment to Bitcoin wallet 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa\",\n",
    "        \"Meeting with Dr. James Wilson at 123 Medical Center, Suite 456, New York, NY 10001\",\n",
    "        \"User @tech_jane (Jane Smith) posted from IP address 192.168.1.1\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display original data\n",
    "print(\"=== Original Dataset ===\")\n",
    "display(df)\n",
    "\n",
    "# Convert to DocumentDataset\n",
    "dataset = DocumentDataset.from_pandas(df, npartitions=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ce042-3c5c-4b86-acd9-74886037354c",
   "metadata": {},
   "source": [
    "## Step 4: Configure Asynchronous LLM PII Modifier\n",
    "Now we'll set up the asynchronous LLM-based PII modifier. This modifier uses [asyncio](https://docs.python.org/3/library/asyncio.html) to send multiple requests to the LLM endpoint concurrently, making it suitable for processing large datasets efficiently. The example below uses a NVIDIA hosted NIM. \n",
    "\n",
    "Using a Self-hosted NIM is the fastest way to run the `AsyncLLMPiiModifier`. Check out the following documentation on how to set up a local NIM:\n",
    "\n",
    " - [NVIDIA NIM](https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html)\n",
    " - [NVIDIA NeMo Framework User Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/datacuration/personalidentifiableinformationidentificationandremoval.html#data-curator-pii)\n",
    "\n",
    "For now, we will skip setting up a local NIM and use an API key generated from [here](https://build.nvidia.com/meta/llama-3_1-70b-instruct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660bfdf-aec6-4cc8-af1f-54520ec76e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your configuration for the LLM\n",
    "NIM_BASE_URL = \"https://integrate.api.nvidia.com/v1\"  # Or a local endpoint like \"http://0.0.0.0:8000/v1\"\n",
    "NIM_API_KEY = \"API key\"\n",
    "MODEL_NAME = \"meta/llama-3.1-70b-instruct\"  # Or your desired model compatible with the endpoint\n",
    "MAX_CONCURRENT_REQUESTS = 10  # Adjust based on your endpoint capacity and rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c668f52",
   "metadata": {},
   "source": [
    "Note: `MAX_CONCURRENT_REQUESTS` will be determined by desired throughput threshold and resource availability. Larger models will typically need more resources per request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401e5fc-2110-4f58-8581-fc04ea3a825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the async PII modifier\n",
    "# You can customize 'pii_labels' or provide a custom 'system_prompt'\n",
    "# See nemo_curator.utils.llm_pii_utils for default prompt and labels\n",
    "async_modifier = AsyncLLMPiiModifier(\n",
    "    base_url=NIM_BASE_URL,\n",
    "    api_key=NIM_API_KEY,\n",
    "    model=MODEL_NAME,\n",
    "    max_concurrent_requests=MAX_CONCURRENT_REQUESTS,\n",
    "    # pii_labels=[\"PERSON\", \"EMAIL_ADDRESS\"], # Example: Only detect specific labels # noqa: ERA001\n",
    "    language=\"en\",  # Default is 'English'\n",
    "    # system_prompt=\"Your custom system prompt here...\" # Advanced: Define a custom prompt # noqa: ERA001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b4095-0cd3-440b-983e-cd50a000ef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Async LLM Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Contact {{PERSON}} at {{EMAIL_ADDRESS}} or cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Patient ID: {{PATIENT_ID}}, SSN: {{SSN}}, DOB:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Send payment to {{LOCATION}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meeting with {{PERSON}} at {{LOCATION}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User {{PERSON}} posted from IP address {{LOCAT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                               text\n",
       "0       1  Contact {{PERSON}} at {{EMAIL_ADDRESS}} or cal...\n",
       "1       2  Patient ID: {{PATIENT_ID}}, SSN: {{SSN}}, DOB:...\n",
       "2       3                       Send payment to {{LOCATION}}\n",
       "3       4            Meeting with {{PERSON}} at {{LOCATION}}\n",
       "4       5  User {{PERSON}} posted from IP address {{LOCAT..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 2 partition(s)\n",
      "\n",
      "Results saved to: output_files_async\n"
     ]
    }
   ],
   "source": [
    "# Perform async LLM-based PII redaction\n",
    "\n",
    "async_modified = Modify(async_modifier)(dataset)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"output_files_async\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Display results\n",
    "    print(\"\\n=== Async LLM Results ===\")\n",
    "    modified_df = async_modified.to_pandas()  # Convert directly to Pandas\n",
    "    display(modified_df)\n",
    "\n",
    "    # Save results using DocumentDataset's to_json method\n",
    "    async_modified.to_json(\n",
    "        output_path=output_dir,\n",
    "        write_to_filename=False,  # This ensures proper partitioning into .part files\n",
    "        keep_filename_column=False,\n",
    "    )\n",
    "    print(f\"\\nResults saved to: {output_dir}\")\n",
    "\n",
    "    # Optionally also save as Parquet for better performance with large datasets\n",
    "    parquet_dir = f\"{output_dir}_parquet\"\n",
    "    os.makedirs(parquet_dir, exist_ok=True)\n",
    "    async_modified.to_parquet(output_path=parquet_dir, write_to_filename=False, keep_filename_column=False)\n",
    "    print(f\"Results also saved as Parquet in: {parquet_dir}\")\n",
    "\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"IO error saving results: {e!s}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Value error: {e!s}\")\n",
    "\n",
    "# Optional: Shutdown Dask client if started\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a735a15-e77d-4984-b40a-b902af7ed1b0",
   "metadata": {},
   "source": [
    "Make sure the Dask workers are still up and running. If they are closed, use the `get_client` command to bring it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d09fc-2a41-4e7e-b613-a0287eb5111c",
   "metadata": {},
   "source": [
    "## Step 5: Configure Synchronous LLM PII Modifier\n",
    "\n",
    "Let's also apply the synchronous LLM-based PII modifier to the dataset. This produces the same results as the asynchronous modifier, but is slower on larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b177c02-0dba-4b07-8e2c-af67c854afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_modifier = LLMPiiModifier(\n",
    "    base_url=NIM_BASE_URL,\n",
    "    api_key=NIM_API_KEY,\n",
    "    model=MODEL_NAME,\n",
    "    # pii_labels=[\"PERSON\", \"EMAIL_ADDRESS\"], # Example: Only detect specific labels # noqa: ERA001\n",
    "    language=\"en\",  # Default is English\n",
    "    # system_prompt=\"Your custom system prompt here...\" # noqa: ERA001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38bf9f-1286-4f8a-bc65-079b42cc7c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sync LLM Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Contact {{PERSON}} at {{EMAIL_ADDRESS}} or cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Patient ID: {{PATIENT_ID}}, SSN: {{SSN}}, DOB:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Send payment to {{LOCATION}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meeting with {{PERSON}} at {{LOCATION}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User {{PERSON}} posted from IP address {{LOCAT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                               text\n",
       "0       1  Contact {{PERSON}} at {{EMAIL_ADDRESS}} or cal...\n",
       "1       2  Patient ID: {{PATIENT_ID}}, SSN: {{SSN}}, DOB:...\n",
       "2       3                       Send payment to {{LOCATION}}\n",
       "3       4            Meeting with {{PERSON}} at {{LOCATION}}\n",
       "4       5  User {{PERSON}} posted from IP address {{LOCAT..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 2 partition(s)\n"
     ]
    }
   ],
   "source": [
    "# Perform synchronous LLM-based PII redaction\n",
    "sync_modified = Modify(sync_modifier)(dataset)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== Sync LLM Results ===\")\n",
    "modified = sync_modified.to_pandas()  # Convert directly to Pandas\n",
    "display(modified)\n",
    "\n",
    "\n",
    "# Save sync results\n",
    "sync_modified.to_json(\"sync_modified_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02017e8f-4b81-45dc-a815-643f6bb1d4b0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully demonstrated how NVIDIA NeMo Curator's LLM-based PII modifiers can intelligently transform text data. We explored both the `AsyncLLMPiiModifier` and `LLMPiiModifier`, highlighting their distinct approaches to privacy protection while preserving data utility.\n",
    "\n",
    "We observed that both `AsyncLLMPiiModifier` and `LLMPiiModifier` accurately modify PII. However, for larger datasets, the asynchronous approach is recommended for substantial data volumes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
