{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1bfd87d-271b-4bc9-b824-57887bb1a510",
   "metadata": {},
   "source": [
    "## LLM-based PII Modification on Enron Email Dataset with NeMo Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2906c-3616-4932-825c-0d0e1a461044",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates how to use NeMo Curator's PII (Personally Identifiable Information) modification capabilities on a real-world dataset. We'll use a subset of the Enron email dataset to showcase both asynchronous and synchronous LLM-based PII modification approaches.\n",
    "\n",
    "## Why PII Modification?\n",
    "\n",
    "PII modification is crucial for:\n",
    "1. **Data Privacy with Utility**: Transforming sensitive information while maintaining data usefulness\n",
    "2. **Training Data Quality**: Creating realistic but privacy-safe training data\n",
    "3. **Regulatory Compliance**: Meeting privacy requirements while preserving data characteristics\n",
    "4. **Research Value**: Enabling research on sensitive datasets without compromising privacy\n",
    "5. **Safe ML Training**: Ensuring ML models don't learn or expose private information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b0744",
   "metadata": {},
   "source": [
    "## Example Transformations\n",
    "\n",
    "Original Email:\n",
    "\n",
    "```\n",
    "From: john.doe@enron.com\n",
    "\n",
    "Subject: Meeting with Sarah\n",
    "\n",
    "Hi Sarah, Please call me at (555) 123-4567 to discuss the project.\n",
    "```\n",
    "\n",
    "After PII Redaction:\n",
    "\n",
    "```\n",
    "From: [EMAIL]\n",
    "\n",
    "Subject: Meeting with [PERSON]\n",
    "\n",
    "Hi [PERSON], Please call me at [PHONE_NUMBER] to discuss the project.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b344483f-306e-4fc1-b609-1d1feee6bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nemo_curator.datasets import DocumentDataset\n",
    "from nemo_curator.modifiers.async_llm_pii_modifier import AsyncLLMPiiModifier\n",
    "from nemo_curator.modifiers.llm_pii_modifier import LLMPiiModifier\n",
    "from nemo_curator.modules.modify import Modify\n",
    "from nemo_curator.utils.distributed_utils import get_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d654a-79aa-4d96-bb8f-716f390a0f83",
   "metadata": {},
   "source": [
    "# Download Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b626b42-4718-4579-a6d8-e50b7a0dbcf4",
   "metadata": {},
   "source": [
    "## Dataset Information\n",
    "\n",
    "The [Enron Email Dataset](https://www.cs.cmu.edu/~enron/) is a large public dataset containing real-world business emails from Enron Corporation employees. It was made public during the legal investigation of the Enron corporation and has become a valuable resource for research in natural language processing and email analysis.\n",
    "\n",
    "## Structure\n",
    "The dataset is organized as follows:\n",
    "```\n",
    "- maildir/\n",
    "  - user1/\n",
    "    - inbox/\n",
    "    - sent/\n",
    "    - deleted_items/\n",
    "    ...\n",
    "  - user2/\n",
    "    ...\n",
    "```\n",
    "In this tutorial, we will focus on extracting and processing emails from Philip Allen's mailbox (`allen-p`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4112fc8-21c0-4b98-b19d-906641a2849e",
   "metadata": {},
   "source": [
    "## Step 1: Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfdd89c-bdf2-43dc-8947-4457ced06598",
   "metadata": {},
   "source": [
    "This function downloads the Enron email dataset directly from the official CMU source if it is not already present locally. Having a local copy of the dataset allows you to efficiently experiment with PII redaction and other text processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e475aee-bf56-4857-bbaa-465579ff5593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Enron dataset from https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 443M/443M [00:49<00:00, 8.95MiB/s] \n"
     ]
    }
   ],
   "source": [
    "def download_enron_dataset(target_dir: str = \"enron_data\") -> None:\n",
    "    \"\"\"Download the full Enron email dataset\"\"\"\n",
    "    url = \"https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz\"\n",
    "    tar_file = os.path.join(target_dir, \"enron_mail_20150507.tar.gz\")\n",
    "\n",
    "    # Create target directory\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # Download if not already downloaded\n",
    "    if not os.path.exists(tar_file):\n",
    "        print(f\"Downloading Enron dataset from {url}\")\n",
    "        response = requests.get(url, stream=True, timeout=10)\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        with open(tar_file, \"wb\") as f, tqdm(total=total_size, unit=\"iB\", unit_scale=True, desc=\"Downloading\") as pbar:\n",
    "            for data in response.iter_content(chunk_size=1024 * 1024):\n",
    "                size = f.write(data)\n",
    "                pbar.update(size)\n",
    "    else:\n",
    "        print(f\"Found existing download at {tar_file}\")\n",
    "\n",
    "    return tar_file\n",
    "\n",
    "\n",
    "# Download the dataset\n",
    "tar_file = download_enron_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf94d6b-b3b2-4dbf-918a-8f53ce6c5ef0",
   "metadata": {},
   "source": [
    "## Step 2: Extract Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43fa540-ec0b-41d0-9f57-e5ba08f01dd8",
   "metadata": {},
   "source": [
    "This step extracts all email messages for a specific user (in this case, Allen) from the full Enron dataset archive. Focusing on a single user's mailbox allows to efficiently test and demonstrate PII redaction techniques on a smaller, more manageable set of real-world emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13c5b6-516f-4a22-9681-30081e31b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting allen-p's mailbox...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting allen-p's emails: 100%|██████████| 3044/3044 [00:05<00:00, 581.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted to: enron_data/maildir/allen-p\n",
      "\n",
      "Mailbox structure:\n",
      "allen-p/\n",
      "    sent/\n",
      "        423.\n",
      "        453.\n",
      "        424.\n",
      "        105.\n",
      "        73.\n",
      "        ... (557 more files)\n",
      "    _sent_mail/\n",
      "        423.\n",
      "        453.\n",
      "        424.\n",
      "        105.\n",
      "        73.\n",
      "        ... (597 more files)\n",
      "    inbox/\n",
      "        73.\n",
      "        41.\n",
      "        21.\n",
      "        22.\n",
      "        3.\n",
      "        ... (61 more files)\n",
      "    notes_inbox/\n",
      "        41.\n",
      "        21.\n",
      "        22.\n",
      "        3.\n",
      "        11.\n",
      "        ... (43 more files)\n",
      "    all_documents/\n",
      "        423.\n",
      "        453.\n",
      "        424.\n",
      "        105.\n",
      "        73.\n",
      "        ... (623 more files)\n",
      "    discussion_threads/\n",
      "        423.\n",
      "        453.\n",
      "        424.\n",
      "        105.\n",
      "        73.\n",
      "        ... (407 more files)\n",
      "    contacts/\n",
      "        2.\n",
      "        1.\n",
      "    straw/\n",
      "        3.\n",
      "        2.\n",
      "        5.\n",
      "        8.\n",
      "        4.\n",
      "        ... (3 more files)\n",
      "    sent_items/\n",
      "        105.\n",
      "        73.\n",
      "        299.\n",
      "        173.\n",
      "        266.\n",
      "        ... (340 more files)\n",
      "    deleted_items/\n",
      "        423.\n",
      "        453.\n",
      "        424.\n",
      "        105.\n",
      "        73.\n",
      "        ... (356 more files)\n"
     ]
    }
   ],
   "source": [
    "def extract_user_mailbox(tar_file: str, username: str = \"allen-p\", target_dir: str = \"enron_data\") -> None:\n",
    "    \"\"\"Extract specific user's mailbox from the dataset\"\"\"\n",
    "    maildir_path = os.path.join(target_dir, \"maildir\")\n",
    "    user_path = os.path.join(maildir_path, username)\n",
    "\n",
    "    if not os.path.exists(user_path):\n",
    "        print(f\"Extracting {username}'s mailbox...\")\n",
    "        with tarfile.open(tar_file, \"r:gz\") as tar:\n",
    "            # Get all members that belong to the specified user\n",
    "            members = [m for m in tar.getmembers() if m.name.startswith(f\"maildir/{username}/\")]\n",
    "\n",
    "            # Extract user's mailbox\n",
    "            for member in tqdm(members, desc=f\"Extracting {username}'s emails\"):\n",
    "                tar.extract(member, target_dir)\n",
    "    else:\n",
    "        print(f\"Found existing extraction at {user_path}\")\n",
    "\n",
    "    return user_path\n",
    "\n",
    "\n",
    "# Extract Allen's mailbox\n",
    "allen_path = extract_user_mailbox(tar_file, username=\"allen-p\")\n",
    "print(f\"\\nExtracted to: {allen_path}\")\n",
    "\n",
    "# List contents of Allen's mailbox\n",
    "print(\"\\nMailbox structure:\")\n",
    "MAX_FILES_TO_SHOW = 5\n",
    "for root, _dirs, files in os.walk(allen_path):\n",
    "    level = root.replace(allen_path, \"\").count(os.sep)\n",
    "    indent = \" \" * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    if files:\n",
    "        subindent = \" \" * 4 * (level + 1)\n",
    "        for f in files[:MAX_FILES_TO_SHOW]:  # Show first 5 files in each directory\n",
    "            print(f\"{subindent}{f}\")\n",
    "        if len(files) > MAX_FILES_TO_SHOW:\n",
    "            print(f\"{subindent}... ({len(files) - 5} more files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c3033-36fe-434e-b149-18c1ef187fcd",
   "metadata": {},
   "source": [
    "## Step 3: Load Sample Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8682b-d6dc-416d-b3eb-8aefe1ef8a76",
   "metadata": {},
   "source": [
    "This step reads a selection of raw email files from the extracted user mailbox (Allen-P) and loads them into a structured DataFrame, preparing the data for further processing and PII redaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945539bd-1735-4965-8d24-54bab42a2286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading emails from enron_data/maildir/allen-p/inbox\n",
      "\n",
      "Loaded 10 emails\n",
      "\n",
      "Sample DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         10 non-null     object\n",
      " 1   text       10 non-null     object\n",
      " 2   file_path  10 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 368.0+ bytes\n",
      "None\n",
      "\n",
      "First email preview (first 300 characters):\n",
      "Message-ID: <17733064.1075862166101.JavaMail.evans@thyme>\n",
      "Date: Tue, 27 Nov 2001 17:05:30 -0800 (PST)\n",
      "From: jwills3@swbell.net\n",
      "To: k..allen@enron.com\n",
      "Subject: Re: PO spreadsheets\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: James Wills <jwills3\n"
     ]
    }
   ],
   "source": [
    "def load_emails_from_folder(folder_path: str, max_emails: int = 10) -> list[dict]:\n",
    "    \"\"\"Load emails from a specific folder\"\"\"\n",
    "    emails = []\n",
    "    email_count = 0\n",
    "\n",
    "    print(f\"Loading emails from {folder_path}\")\n",
    "    for file in os.listdir(folder_path):\n",
    "        if email_count >= max_emails:\n",
    "            break\n",
    "\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            with open(file_path, encoding=\"latin-1\") as f:\n",
    "                content = f.read()\n",
    "                # Basic validation that it's an email\n",
    "                if \"Message-ID:\" in content or \"Date:\" in content:\n",
    "                    emails.append({\"id\": f\"allen-p_{email_count}\", \"text\": content, \"file_path\": file_path})\n",
    "                    email_count += 1\n",
    "        except (OSError, UnicodeDecodeError) as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(emails)\n",
    "\n",
    "\n",
    "# Load sample emails from Allen's inbox\n",
    "inbox_path = os.path.join(allen_path, \"inbox\")\n",
    "sample_df = load_emails_from_folder(inbox_path, max_emails=10)\n",
    "\n",
    "print(f\"\\nLoaded {len(sample_df)} emails\")\n",
    "print(\"\\nSample DataFrame info:\")\n",
    "print(sample_df.info())\n",
    "\n",
    "# Show preview of first email\n",
    "print(\"\\nFirst email preview (first 300 characters):\")\n",
    "print(sample_df.iloc[0][\"text\"][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5875d29-836c-415b-a7a1-bdce35e33f6e",
   "metadata": {},
   "source": [
    "## Step 4: Convert to `DocumentDataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66d591-3a2e-49bb-bda4-9e620bf99bcd",
   "metadata": {},
   "source": [
    "NeMo Curator requires conversion of your DataFrame to a `DocumentDataset` format for efficient, compatibility and seamless integration with LLM-based PII redaction and text modification tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00490d1-b6c2-4ccf-b81d-dd8608d9750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DocumentDataset.from_pandas(sample_df, npartitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27870557-a13a-4305-999c-86cbbc0a8b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <1449918.1075858645402.JavaMail.evans@thyme>\n",
      "Date: Mon, 29 Oct 2001 17:35:18 -0800 (PST)\n",
      "From: arsystem@mailman.enron.com\n",
      "To: k..allen@enron.com\n",
      "Subject: Your Approval is Overdue: Access Request for matt.smith@enron.com\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: ARSystem <ARSystem@mailman.enron.com>@ENRON\n",
      "X-To: Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENTS/CN=PALLEN>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Inbox\n",
      "X-Origin: Allen-P\n",
      "X-FileName: PALLEN (Non-Privileged).pst\n",
      "\n",
      "This request has been pending your approval for  14 days.  Please click http://itcapps.corp.enron.com/srrs/auth/emailLink.asp?ID=000000000067320&Page=Approval to review and act upon this request.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Request ID          : 000000000067320\n",
      "Request Create Date : 10/11/01 10:24:53 AM\n",
      "Requested For       : matt.smith@enron.com\n",
      "Resource Name       : Risk Acceptance Forms Local Admin Rights - Permanent\n",
      "Resource Type       : Applications\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View a sample email in its original form\n",
    "print(sample_df[\"text\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25d9dc-fa9b-468d-ac1d-d45e1d1bf6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p_0</td>\n",
       "      <td>Message-ID: &lt;17733064.1075862166101.JavaMail.e...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/73.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p_1</td>\n",
       "      <td>Message-ID: &lt;1449918.1075858645402.JavaMail.ev...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/41.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p_2</td>\n",
       "      <td>Message-ID: &lt;8113917.1075858644677.JavaMail.ev...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/21.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p_3</td>\n",
       "      <td>Message-ID: &lt;5393535.1075858644700.JavaMail.ev...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/22.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p_4</td>\n",
       "      <td>Message-ID: &lt;10326858.1075855377484.JavaMail.e...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allen-p_5</td>\n",
       "      <td>Message-ID: &lt;7462038.1075855377703.JavaMail.{{...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/11.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allen-p_6</td>\n",
       "      <td>Message-ID: &lt;2467021.1075862165862.JavaMail.ev...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/63.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allen-p_7</td>\n",
       "      <td>Message-ID: &lt;12246129.1075858645002.JavaMail.e...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/33.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allen-p_8</td>\n",
       "      <td>Message-ID: &lt;14859009.1075862166148.JavaMail.e...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/75.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>allen-p_9</td>\n",
       "      <td>Message-ID: &lt;11341209.1075858645204.JavaMail.e...</td>\n",
       "      <td>enron_data/maildir/allen-p/inbox/35.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0  allen-p_0  Message-ID: <17733064.1075862166101.JavaMail.e...   \n",
       "1  allen-p_1  Message-ID: <1449918.1075858645402.JavaMail.ev...   \n",
       "2  allen-p_2  Message-ID: <8113917.1075858644677.JavaMail.ev...   \n",
       "3  allen-p_3  Message-ID: <5393535.1075858644700.JavaMail.ev...   \n",
       "4  allen-p_4  Message-ID: <10326858.1075855377484.JavaMail.e...   \n",
       "5  allen-p_5  Message-ID: <7462038.1075855377703.JavaMail.{{...   \n",
       "6  allen-p_6  Message-ID: <2467021.1075862165862.JavaMail.ev...   \n",
       "7  allen-p_7  Message-ID: <12246129.1075858645002.JavaMail.e...   \n",
       "8  allen-p_8  Message-ID: <14859009.1075862166148.JavaMail.e...   \n",
       "9  allen-p_9  Message-ID: <11341209.1075858645204.JavaMail.e...   \n",
       "\n",
       "                              file_path  \n",
       "0  enron_data/maildir/allen-p/inbox/73.  \n",
       "1  enron_data/maildir/allen-p/inbox/41.  \n",
       "2  enron_data/maildir/allen-p/inbox/21.  \n",
       "3  enron_data/maildir/allen-p/inbox/22.  \n",
       "4   enron_data/maildir/allen-p/inbox/3.  \n",
       "5  enron_data/maildir/allen-p/inbox/11.  \n",
       "6  enron_data/maildir/allen-p/inbox/63.  \n",
       "7  enron_data/maildir/allen-p/inbox/33.  \n",
       "8  enron_data/maildir/allen-p/inbox/75.  \n",
       "9  enron_data/maildir/allen-p/inbox/35.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view the dataset content (DocumentDataset), convert it to a Pandas DataFrame and display the first few rows\n",
    "dataset.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba35aa-331e-4d76-b118-53af3f61c6f6",
   "metadata": {},
   "source": [
    "## Step 5: Configure and Apply LLM-based PII Modifiers\n",
    "Below, we use an NVIDIA-hosted NIM with an API key generated from [here](https://build.nvidia.com/meta/llama-3_1-70b-instruct). To set up a self-hosted NIM, please refer to the [NIM documentation](https://docs.nvidia.com/nim/large-language-models/latest/configuration.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b42fb5-23ed-4d79-a16d-c2971fe86bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42727 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacting with asynchronous LLM-based modifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:04<00:13,  4.39s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:04<00:03,  1.87s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.21s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:12<00:12, 12.86s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.46s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.26it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.56it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.63it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.86s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:05<00:05,  2.66s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:08<00:02,  2.76s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.67s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:14<00:14, 14.69s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.72s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:23<00:00, 11.71s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.35it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:11<00:11, 11.63s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 2 partition(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Redacting with synchronous LLM-based modifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.22it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:00<00:00,  4.05it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.41s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.31it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.17it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.31s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:09<00:09,  9.23s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.82s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:06<00:06,  3.23s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.50s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.59s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:14<00:14, 14.38s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:22<00:00, 11.42s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.22it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:00<00:00,  3.27it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.29s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:05<00:05,  5.15s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 2 partition(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.06it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:05<00:06,  3.18s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:05<00:01,  1.89s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.57s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.29s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.70s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.18it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.09s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:08<00:08,  8.35s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.41s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.21it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:00<00:00,  3.20it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.24it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.61s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:06<00:06,  6.41s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.85s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.13s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.16it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:00<00:00,  3.36it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.27it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:04<00:04,  4.65s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:38<00:00, 38.57s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:43<00:00, 21.61s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.73it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.13it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:06<00:02,  2.70s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [00:08<00:08,  8.15s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Configure asynchronous LLM-based PII modifier\n",
    "client = get_client()\n",
    "async_modifier = AsyncLLMPiiModifier(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",  # Replace with your endpoint\n",
    "    api_key=\"\",  # Replace with your API key\n",
    "    model=\"meta/llama-3.1-70b-instruct\",\n",
    "    max_concurrent_requests=10,\n",
    "    # pii_labels=[\"PERSON\", \"EMAIL_ADDRESS\"], # Example: Only detect specific labels # noqa: ERA001\n",
    "    language=\"en\",  # Default is 'English'\n",
    ")\n",
    "\n",
    "# Configure synchronous LLM-based  PII modifier\n",
    "sync_modifier = LLMPiiModifier(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",  # Replace with your endpoint\n",
    "    api_key=\"\",  # Replace with your API key\n",
    "    model=\"meta/llama-3.1-70b-instruct\",\n",
    "    # pii_labels=[\"PERSON\", \"EMAIL_ADDRESS\"], # Example: Only detect specific labels # noqa: ERA001\n",
    "    language=\"en\",  # Default is 'English'\n",
    ")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"output/async_llm_enron\", exist_ok=True)\n",
    "os.makedirs(\"output/sync_llm_enron\", exist_ok=True)\n",
    "\n",
    "# Perform redaction with both modifiers\n",
    "print(\"Redacting with asynchronous LLM-based modifier...\")\n",
    "modify_async = Modify(async_modifier, text_field=\"text\")\n",
    "modified_async = modify_async(dataset)\n",
    "modified_async.to_json(\"output/async_llm_enron\", write_to_filename=False)\n",
    "\n",
    "print(\"\\nRedacting with synchronous LLM-based modifier...\")\n",
    "modify_sync = Modify(sync_modifier, text_field=\"text\")\n",
    "modified_sync = modify_sync(dataset)\n",
    "modified_sync.to_json(\"output/sync_llm_enron\", write_to_filename=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736c973-9e29-4d3d-8fcd-40e2113076ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <17733064.1075862166101.JavaMail.evans@thyme>\n",
      "Date: {{DATE}}\n",
      "From: {{EMAIL_ADDRESS}}\n",
      "To: {{PERSON}}@enron.com\n",
      "Subject: Re: PO spreadsheets\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: {{PERSON}} <{{EMAIL_ADDRESS}}>@ENRON\n",
      "X-To: {{PERSON}} </O=ENRON/OU=NA/CN=RECIPIENTS/CN=PALLEN>, {{EMAIL_ADDRESS}}\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\PALLEN (Non-Privileged)\\{{PERSON}}\\Inbox\n",
      "X-Origin: Allen-P\n",
      "X-FileName: PALLEN (Non-Privileged).pst\n",
      "\n",
      "{{PERSON}}, the insurance/repairs numbers are actually overstated; they are based on calculations from USPSL owners and agents like us who have helped clients buy and sell post offices for years. With regards to the exercising of renewal options, you might be interested to know that the USPS actually renews these 94% of the time; some post offices are in the 75 years and above range on leases. And finally, the construction  costs are reflective of the construction codes and practices the USPS requires for contractors. These are well-built facilities, last a long time, and can be converted to many other uses if the post office moves out.\n",
      "\n",
      "I have added another post office for your consideration. It's in {{LOCATION}}, is a multi-tenant building, and has a fairly strong cap rate. The flyer is attached.\n",
      "\n",
      "In any case, I would be glad to help you look for other investment possibilities over here. Do let me know what you've already found, and what you might like to find. I look forward to hearing from you. With best regards, {{PERSON}}\n",
      "\n",
      "{{EMAIL_ADDRESS}} wrote:\n",
      "\n",
      "> Jim,\n",
      ">\n",
      "> Your spreadsheet shows the same type of return I was calculating.  Your\n",
      "> insurance and repair numbers seem very low.   Also, assuming that the\n",
      "> options to extend at higher rates will be exercised is a huge leap of\n",
      "> faith.  I don't believe these properties cost any where near the $150+/sf\n",
      "> that they are being offered at.\n",
      ">\n",
      "> Based on the optimistic back loaded returns, I would not be comfortable\n",
      "> purchasing a post office at this time.  Thank you anyway.\n",
      ">\n",
      "> {{PERSON}}\n",
      ">\n",
      ">       -----Original Message-----\n",
      ">      From:   {{PERSON}} <{{EMAIL_ADDRESS}}>@ENRON\n",
      ">      Sent:   {{DATE}}\n",
      ">      To:     {{EMAIL_ADDRESS}}; {{EMAIL_ADDRESS}}\n",
      ">      Subject:  PO spreadsheets\n",
      ">\n",
      ">      {{PERSON}},\n",
      ">\n",
      ">      Hope you are doing well this week, and have great plans for\n",
      ">      {{DATE}}!!\n",
      ">      We'll be with family in {{LOCATION}}, and kind of on a maiden voyage in our\n",
      ">      '83 Avion that we're upgrading for camping!\n",
      ">\n",
      ">      Here's a look at three post offices in a slightly different manner.\n",
      ">      Remember that the Roma one is about 5 years old, was a 15 yr lease\n",
      ">      originally. The other two are new.\n",
      ">\n",
      ">      The Roma is like buying a savings account. It would be paid off in 10\n",
      ">      years, you would reap some cash flow during that period, then the\n",
      ">      bonus\n",
      ">      kicks in after that with the 10 yr. renewals at a higher lease income\n",
      ">      after it's paid off. It would probably go beyond another 10 years.\n",
      ">      Cash\n",
      ">      on cash returns don't mean as much on shorter amoritazations like\n",
      ">      Roma.\n",
      ">\n",
      ">      We have shown this info and flyers to several people, so do let us\n",
      ">      know\n",
      ">      if you are interested in any of them...I really don't think they will\n",
      ">      last long. With best regards, {{PERSON}}\n",
      ">\n",
      ">       - new analysis.xls << File: new analysis.xls >>\n",
      ">\n",
      "> **********************************************************************\n",
      "> This e-mail is the property of Enron Corp. and/or its relevant affiliate and may contain confidential and privileged material for the sole use of the intended recipient (s). Any review, use, distribution or disclosure by others is strictly prohibited. If you are not the intended recipient (or authorized to receive for the recipient), please contact the sender or reply to Enron Corp. at {{EMAIL_ADDRESS}} and delete all copies of the message. This e-mail (and any attachments hereto) are not intended to be an offer (or an acceptance) and do not create or evidence a binding and enforceable contract between Enron Corp. (or any of its affiliates) and the intended recipient or any other party, and may not be relied on by anyone as the basis of a contract by estoppel or otherwise. Thank you.\n",
      "> **********************************************************************\n",
      "\n",
      " - {{LOCATION}}.wps.doc \n"
     ]
    }
   ],
   "source": [
    "# Let's check out one of the emails after async modification\n",
    "print(modified_async.df.head(1).iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e7e80-3e43-4c01-a4ae-8af881a34a44",
   "metadata": {},
   "source": [
    "The steps above successfully identified and redacted various types of PII, such as email addresses and locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e599c81-08c3-4180-ac6f-41962a422040",
   "metadata": {},
   "source": [
    "## Step 6: Compare Results\n",
    "This section showcases how certain PII (such as like email addresses) changed after using the PII modifiers. We also examine some statistics about the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a8730-5122-4b19-8875-c31b433ef356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comparison analysis...\n",
      "\n",
      "=== ORIGINAL EMAIL ===\n",
      "Message-ID: <17733064.1075862166101.JavaMail.evans@thyme>\n",
      "Date: Tue, 27 Nov 2001 17:05:30 -0800 (PST)\n",
      "From: jwills3@swbell.net\n",
      "To: k..allen@enron.com\n",
      "Subject: Re: PO spreadsheets\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: James Wills <jwills3\n",
      "\n",
      "=== ASYNC LLM MODIFIED ===\n",
      "Message-ID: <17733064.1075862166101.JavaMail.evans@thyme>\n",
      "Date: Tue, 27 Nov 2001 17:05:30 -0800 (PST)\n",
      "From: {{email}}\n",
      "To: k..allen@enron.com\n",
      "Subject: Re: PO spreadsheets\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: {{name}} <{{email}}>@ENRON\n",
      "X-\n",
      "\n",
      "=== SYNC LLM MODIFIED ===\n",
      "Message-ID: <17733064.1075862166101.JavaMail.evans@thyme>\n",
      "Date: Tue, 27 Nov 2001 17:05:30 -0800 (PST)\n",
      "From: {{email}}\n",
      "To: k..allen@enron.com\n",
      "Subject: Re: PO spreadsheets\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: {{name}} <{{email}}>@ENRON\n",
      "X-\n",
      "\n",
      "=== How Much Did the Emails Change? ===\n",
      "Original email was 4421 characters long\n",
      "Async modified version is 4355 characters (changed by -66 characters)\n",
      "Sync modified version is 4355 characters (changed by -66 characters)\n"
     ]
    }
   ],
   "source": [
    "def compare_pii_modifications(\n",
    "    sample_df: pd.DataFrame, modified_async: pd.DataFrame, modified_sync: pd.DataFrame, idx: int = 0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Compare the original, async-modified, and sync-modified versions of an email.\n",
    "    Also show how much the email length changed after PII redaction.\n",
    "    \"\"\"\n",
    "    # Extract the email text for the selected index\n",
    "    original_email = sample_df[\"text\"].iloc[idx]\n",
    "    async_email = modified_async.to_pandas()[\"text\"].iloc[idx]\n",
    "    sync_email = modified_sync.to_pandas()[\"text\"].iloc[idx]\n",
    "\n",
    "    print(\"\\n=== ORIGINAL EMAIL ===\")\n",
    "    print(original_email[:300])\n",
    "\n",
    "    print(\"\\n=== ASYNC LLM MODIFIED ===\")\n",
    "    print(async_email[:300])\n",
    "\n",
    "    print(\"\\n=== SYNC LLM MODIFIED ===\")\n",
    "    print(sync_email[:300])\n",
    "\n",
    "    # Show how much the length changed\n",
    "    print(\"\\n=== How Much Did the Emails Change? ===\")\n",
    "    print(f\"Original email was {len(original_email)} characters long\")\n",
    "    print(\n",
    "        f\"Async modified version is {len(async_email)} characters (changed by {len(async_email) - len(original_email)} characters)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sync modified version is {len(sync_email)} characters (changed by {len(sync_email) - len(original_email)} characters)\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Starting comparison analysis...\")\n",
    "compare_pii_modifications(sample_df, modified_async, modified_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a69033-df1f-41dd-8355-992113cb77d3",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "- Both methods preserved the email's structure and business content\n",
    "- Since both PII modifiers used the same LLM, they produced the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1f5a6-e18a-41c0-aa07-d4135983db49",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This tutorial has demonstrated a practical implementation of PII modification using NeMo Curator's LLM-based modifiers on the Enron email dataset. \n",
    "\n",
    "The PII modification process used an NVIDIA-hosted LLM to identify and redact personally identifiable information in the emails. Every PII identified was replaced by a generic such as `{{name}}` and `{{email}}`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
