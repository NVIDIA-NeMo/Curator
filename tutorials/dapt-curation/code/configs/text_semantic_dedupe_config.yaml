# Configuration file for semdantic dedup
cache_dir: "workspace/semdedup_cache/text"
num_files: 16

# Embeddings configuration
embedding_model_name_or_path: "sentence-transformers/all-MiniLM-L6-v2"
embedding_batch_size: 128
embeddings_save_loc: "embeddings"
write_embeddings_to_disk: false

# Clustering configuration
max_iter: 100
n_clusters: 15
clustering_save_loc: "clustering_results"
sim_metric: "cosine"
which_to_keep: "hard"
batched_cosine_similarity: 1024
clustering_input_partition_size: "2gb"

# Extract dedup configuration
# Which threshold to use for extracting deduped data
eps_to_extract: 0.1
