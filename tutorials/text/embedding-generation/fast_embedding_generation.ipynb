{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eef54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "os.environ[\"LOGURU_LEVEL\"] = \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b188ed",
   "metadata": {},
   "source": [
    "## Modify Resources(gpus) in EmbeddingGeneration to speedup\n",
    "\n",
    "Please note this is dependent on model used and GPU sku. \n",
    "\n",
    "Assuming < 50% is being utilized we can expect speedup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edc695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73871b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_curator.stages.resources import Resources\n",
    "from nemo_curator.stages.text.embedders import EmbeddingCreatorStage\n",
    "from nemo_curator.stages.text.models.utils import format_name_with_suffix\n",
    "\n",
    "embedding_creator = EmbeddingCreatorStage(model_identifier=model_name, model_inference_batch_size=256)\n",
    "\n",
    "embedding_creator_half_gpu = EmbeddingCreatorStage(model_identifier=model_name, model_inference_batch_size=256).with_(\n",
    "    {format_name_with_suffix(model_name, \"_model\"): {\"resources\": Resources(gpus=0.5)}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414ba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:44:39,539\tINFO worker.py:1691 -- Using address 127.0.1.1:6380 set in the environment variable RAY_ADDRESS\n",
      "2025-11-20 23:44:39,548\tINFO worker.py:1832 -- Connecting to existing Ray cluster at address: 127.0.1.1:6380...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:44:40,950\tINFO usage_lib.py:447 -- Usage stats collection is disabled.\n",
      "2025-11-20 23:44:40,950\tINFO scripts.py:914 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m127.0.1.1\u001b[22m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 23:44:45,799 W 216844 216844] global_state_accessor.cc:505: Some processes that the driver needs to connect to have not registered with GCS, so retrying. Have you run 'ray start' on this node?\n",
      "[2025-11-20 23:44:46,801 W 216844 216844] global_state_accessor.cc:505: Some processes that the driver needs to connect to have not registered with GCS, so retrying. Have you run 'ray start' on this node?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:44:47,452\tSUCC scripts.py:950 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-11-20 23:44:47,452\tSUCC scripts.py:951 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2025-11-20 23:44:47,452\tSUCC scripts.py:952 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-11-20 23:44:47,452\tINFO scripts.py:954 -- \u001b[36mNext steps\u001b[39m\n",
      "2025-11-20 23:44:47,452\tINFO scripts.py:957 -- To add another node to this Ray cluster, run\n",
      "2025-11-20 23:44:47,452\tINFO scripts.py:960 -- \u001b[1m  ray start --address='127.0.1.1:6380'\u001b[22m\n",
      "2025-11-20 23:44:47,452\tINFO scripts.py:969 -- To connect to this Ray cluster:\n",
      "2025-11-20 23:44:47,452\tINFO scripts.py:971 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:972 -- ray\u001b[35m.\u001b[39m\u001b[26minit(_node_ip_address\u001b[35m=\u001b[39m\u001b[26m\u001b[33m'127.0.1.1'\u001b[39m\u001b[26m)\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:984 -- To submit a Ray job using the Ray Jobs CLI:\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:985 -- \u001b[1m  RAY_API_SERVER_ADDRESS='http://127.0.1.1:8266' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:994 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:998 -- for more information on submitting Ray jobs to the Ray cluster.\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1003 -- To terminate the Ray runtime, run\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1004 -- \u001b[1m  ray stop\u001b[22m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1007 -- To view the status of the cluster, use\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1008 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1012 -- To monitor and debug Ray, view the dashboard at \n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1013 --   \u001b[1m127.0.1.1:8266\u001b[22m\u001b[26m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1020 -- \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1121 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1122 -- This command will now block forever until terminated by a signal.\n",
      "2025-11-20 23:44:47,453\tINFO scripts.py:1125 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-20 23:44:47,802 I 216844 216844] global_state_accessor.cc:487: This node has an IP address of 127.0.1.1, but we cannot find a local Raylet with the same address. This can happen when you connect to the Ray cluster with a different IP address or when connecting to a container.\n",
      "2025-11-20 23:44:47,805\tINFO worker.py:2012 -- Connected to Ray cluster.\n",
      "/raid/praateekm/NeMo-Curator/.venv/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 9398.65it/s]\n",
      "2025-11-20 23:44:59,863\tWARNING util.py:597 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2025-11-20 23:45:00,065\tWARNING util.py:597 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2025-11-20 23:45:00,094\tINFO streaming_executor.py:85 -- A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "2025-11-20 23:45:00,095\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_6_0\n",
      "2025-11-20 23:45:00,105\tWARNING map_operator.py:783 -- Specifying both num_cpus and num_gpus for map tasks is experimental, and may result in scheduling or stability issues. Please report any issues to the Ray team: https://github.com/ray-project/ray/issues/new/choose\n",
      "2025-11-20 23:45:00,105\tINFO streaming_executor.py:170 -- Starting execution of Dataset dataset_6_0. Full logs are in /raid/praateekm/ray_temp/b49a36/session_2025-11-20_23-44-40_951218_217438/logs/ray-data\n",
      "2025-11-20 23:45:00,106\tINFO streaming_executor.py:171 -- Execution plan of Dataset dataset_6_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(FilePartitioningStageTask)] -> TaskPoolMapOperator[StreamingRepartition] -> ActorPoolMapOperator[MapBatches(ParquetReaderStageTask)->MapBatches(TokenizerStageActor)] -> ActorPoolMapOperator[MapBatches(EmbeddingModelStageActor)] -> TaskPoolMapOperator[MapBatches(ParquetWriterTask)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ab5a0bec3b46038f867f02b80efa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2292e87276048bc9b177b4926419af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(FilePartitioningStageTask) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240ef03beb204646933b1f697f502bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- StreamingRepartition 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88ae2deeec7470c8071d1cadfa84831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(ParquetReaderStageTask)->MapBatches(TokenizerStageActor) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e722416c7a74999bbd080e75fb95a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(EmbeddingModelStageActor) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c69677edc264d73949dc5e1a9b5db81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(ParquetWriterTask) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:45:00,197\tWARNING resource_manager.py:134 -- ⚠️  Ray's object store is configured to use only 11.7% of available memory (186.3GiB out of 1586.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 9583.33it/s]\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 10450.06it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 11375.93it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 11546.07it/s] \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 12031.85it/s]zerStageActor)) pid=230200)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 138731.11it/s]\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 12957.38it/s]zerStageActor)) pid=230988)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 14770.41it/s]zerStageActor)) pid=231927)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 13778.92it/s]zerStageActor)) pid=232701)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 211833.54it/s]erStageActor)) pid=233467)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 11619.64it/s]zerStageActor)) pid=234342)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 6013.63it/s]izerStageActor)) pid=235228)\u001b[0m \n",
      "2025-11-20 23:48:12,547\tINFO streaming_executor.py:298 -- ✔️  Dataset dataset_6_0 execution finished in 192.44 seconds\n",
      "2025-11-20 23:48:12,552\tINFO util.py:257 -- Exiting prefetcher's background thread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for full_gpu: 213.12328267097473 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:48:14,802\tINFO worker.py:1691 -- Using address 127.0.1.1:6380 set in the environment variable RAY_ADDRESS\n",
      "2025-11-20 23:48:14,810\tINFO worker.py:1832 -- Connecting to existing Ray cluster at address: 127.0.1.1:6380...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:48:16,283\tINFO usage_lib.py:447 -- Usage stats collection is disabled.\n",
      "2025-11-20 23:48:16,284\tINFO scripts.py:914 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m127.0.1.1\u001b[22m\n",
      "2025-11-20 23:48:22,744\tSUCC scripts.py:950 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-11-20 23:48:22,744\tSUCC scripts.py:951 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2025-11-20 23:48:22,744\tSUCC scripts.py:952 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-11-20 23:48:22,744\tINFO scripts.py:954 -- \u001b[36mNext steps\u001b[39m\n",
      "2025-11-20 23:48:22,744\tINFO scripts.py:957 -- To add another node to this Ray cluster, run\n",
      "2025-11-20 23:48:22,744\tINFO scripts.py:960 -- \u001b[1m  ray start --address='127.0.1.1:6380'\u001b[22m\n",
      "2025-11-20 23:48:22,744\tINFO scripts.py:969 -- To connect to this Ray cluster:\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:971 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:972 -- ray\u001b[35m.\u001b[39m\u001b[26minit(_node_ip_address\u001b[35m=\u001b[39m\u001b[26m\u001b[33m'127.0.1.1'\u001b[39m\u001b[26m)\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:984 -- To submit a Ray job using the Ray Jobs CLI:\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:985 -- \u001b[1m  RAY_API_SERVER_ADDRESS='http://127.0.1.1:8266' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:994 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:998 -- for more information on submitting Ray jobs to the Ray cluster.\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1003 -- To terminate the Ray runtime, run\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1004 -- \u001b[1m  ray stop\u001b[22m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1007 -- To view the status of the cluster, use\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1008 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1012 -- To monitor and debug Ray, view the dashboard at \n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1013 --   \u001b[1m127.0.1.1:8266\u001b[22m\u001b[26m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1020 -- \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1121 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1122 -- This command will now block forever until terminated by a signal.\n",
      "2025-11-20 23:48:22,745\tINFO scripts.py:1125 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:48:23,124\tINFO worker.py:2012 -- Connected to Ray cluster.\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 13438.97it/s]\n",
      "2025-11-20 23:48:34,662\tWARNING util.py:597 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2025-11-20 23:48:34,864\tWARNING util.py:597 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2025-11-20 23:48:34,866\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_6_0\n",
      "2025-11-20 23:48:34,868\tWARNING map_operator.py:783 -- Specifying both num_cpus and num_gpus for map tasks is experimental, and may result in scheduling or stability issues. Please report any issues to the Ray team: https://github.com/ray-project/ray/issues/new/choose\n",
      "2025-11-20 23:48:34,869\tINFO streaming_executor.py:170 -- Starting execution of Dataset dataset_6_0. Full logs are in /raid/praateekm/ray_temp/a0b8be/session_2025-11-20_23-48-16_284531_239854/logs/ray-data\n",
      "2025-11-20 23:48:34,869\tINFO streaming_executor.py:171 -- Execution plan of Dataset dataset_6_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(FilePartitioningStageTask)] -> TaskPoolMapOperator[StreamingRepartition] -> ActorPoolMapOperator[MapBatches(ParquetReaderStageTask)->MapBatches(TokenizerStageActor)] -> ActorPoolMapOperator[MapBatches(EmbeddingModelStageActor)] -> TaskPoolMapOperator[MapBatches(ParquetWriterTask)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11b4f5ab72b4320a2b9c6f90281eb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79be07fe20f14915896cbd306c46489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(FilePartitioningStageTask) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f14fb30d5fb449abd2f49a02fc35cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- StreamingRepartition 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d0662641e24572b16398e69c915e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(ParquetReaderStageTask)->MapBatches(TokenizerStageActor) 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c896caf3c9bf41ec89cba115f6726baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(EmbeddingModelStageActor) 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96b90a30ced46c0822a73ca1dc29491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(ParquetWriterTask) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 10266.74it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 10565.00it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 26915.32it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 8056.16it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 12475.62it/s] \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 12846.26it/s]zerStageActor)) pid=252947)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 121691.61it/s]\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 13665.20it/s]zerStageActor)) pid=253845)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 138425.87it/s]\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 12222.35it/s]zerStageActor)) pid=254674)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 17089.38it/s] \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 14951.18it/s]zerStageActor)) pid=255649)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 17749.91it/s]zerStageActor)) pid=256505)\u001b[0m \n",
      "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]=257304)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 10867.01it/s] \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 10002.31it/s]zerStageActor)) pid=257795)\u001b[0m \n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 11785.06it/s]zerStageActor)) pid=258816)\u001b[0m \n",
      "2025-11-20 23:50:48,058\tINFO streaming_executor.py:298 -- ✔️  Dataset dataset_6_0 execution finished in 133.19 seconds\n",
      "2025-11-20 23:50:48,064\tINFO util.py:257 -- Exiting prefetcher's background thread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for half_gpu: 153.33278346061707 seconds\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from nemo_curator.backends.experimental.ray_data import RayDataExecutor\n",
    "from nemo_curator.core.client import RayClient\n",
    "from nemo_curator.pipeline import Pipeline\n",
    "from nemo_curator.stages.text.io.reader.parquet import ParquetReader\n",
    "from nemo_curator.stages.text.io.writer.parquet import ParquetWriter\n",
    "\n",
    "input_path = \"./tinystories_train_parquet\"\n",
    "output_path = \"./output_path/\"\n",
    "ray_temp_dir = \"/tmp\"  # noqa: S108\n",
    "\n",
    "shutil.rmtree(output_path, ignore_errors=True)\n",
    "\n",
    "time_taken = {}\n",
    "for _embedding_creator, _name in [(embedding_creator, \"full_gpu\"), (embedding_creator_half_gpu, \"half_gpu\")]:\n",
    "    # Ensure RAY_ADDRESS is cleared before starting a new cluster\n",
    "    os.environ[\"RAY_ADDRESS\"] = \"\"\n",
    "    ray_temp_dir_path = os.path.join(ray_temp_dir, str(uuid.uuid4())[:6])\n",
    "    pipeline = Pipeline(\n",
    "        name=_name,\n",
    "        stages=[\n",
    "            ParquetReader(\n",
    "                file_paths=input_path,\n",
    "                fields=[\"text\"],\n",
    "            ),\n",
    "            _embedding_creator,\n",
    "            ParquetWriter(os.path.join(output_path, f\"{_name}_tinystories\")),\n",
    "        ],\n",
    "    )\n",
    "    with RayClient(\n",
    "        num_cpus=64,\n",
    "        num_gpus=4,\n",
    "        ray_temp_dir=ray_temp_dir_path,\n",
    "        ray_dashboard_host=\"0.0.0.0\",  # noqa: S104\n",
    "    ) as client:\n",
    "        t0 = time.time()\n",
    "        pipeline.run(RayDataExecutor())\n",
    "        t1 = time.time()\n",
    "        time_taken[_name] = t1 - t0\n",
    "        print(f\"Time taken for {_name}: {t1 - t0} seconds\")\n",
    "    # Small delay to ensure Ray cluster is fully cleaned up before next iteration\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9520ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for full_gpu: 213.12 seconds\n",
      "Time taken for half_gpu: 153.33 seconds\n"
     ]
    }
   ],
   "source": [
    "for run_name, run_time in time_taken.items():\n",
    "    print(f\"Time taken for {run_name}: {run_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
