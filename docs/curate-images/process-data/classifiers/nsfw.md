---
description: "NSFW classifier for detecting inappropriate content in images using CLIP embeddings and MLP architecture"
categories: ["how-to-guides"]
tags: ["nsfw", "classification", "clip", "safety", "content-filtering"]
personas: ["data-scientist-focused", "mle-focused"]
difficulty: "intermediate"
content_type: "how-to"
modality: "image-only"
---

(image-process-data-classifiers-nsfw)=

# NSFW Classifier

The NSFW (Not Safe For Work) Classifier detects the likelihood that an image contains explicit or unsafe content. It outputs a probability score from 0 (safe) to 1 (NSFW), helping you filter or flag images in your datasets.

## Model Details

- **Architecture:** MLP trained on OpenAI CLIP ViT-L/14 image embeddings
- **Source:** [CLIP-based NSFW Detector](https://github.com/LAION-AI/CLIP-based-NSFW-Detector)
- **Output Field:** `nsfw_score`
- **Score Range:** 0â€“1 (higher is more likely NSFW)
- **Embedding Requirement:** CLIP ViT-L/14 (see {ref}`image-process-data-embeddings`)

## How It Works

The classifier takes normalized image embeddings and predicts the probability of NSFW content. It is lightweight and can be run on the GPU alongside embedding computation for efficient batch processing.

## Usage

:::: {tab-set}

::: {tab-item} Python

```python
from nemo_curator.pipeline import Pipeline
from nemo_curator.stages.file_partitioning import FilePartitioningStage
from nemo_curator.stages.image.io.image_reader import ImageReaderStage
from nemo_curator.stages.image.embedders.clip_embedder import ImageEmbeddingStage
from nemo_curator.stages.image.filters.nsfw_filter import ImageNSFWFilterStage

# Create pipeline
pipeline = Pipeline(name="nsfw_filtering", description="Filter NSFW content from images")

# Stage 1: Partition tar files
pipeline.add_stage(FilePartitioningStage(
    file_paths="/path/to/webdataset",
    files_per_partition=1,
    file_extensions=[".tar"],
))

# Stage 2: Read images
pipeline.add_stage(ImageReaderStage(
    task_batch_size=100,
    num_gpus_per_worker=0.25,
))

# Stage 3: Generate CLIP embeddings
pipeline.add_stage(ImageEmbeddingStage(
    model_dir="/path/to/models",
    model_inference_batch_size=32,
    num_gpus_per_worker=0.25,
))

# Stage 4: Apply NSFW filtering
pipeline.add_stage(ImageNSFWFilterStage(
    model_dir="/path/to/models",
    score_threshold=0.5,
    model_inference_batch_size=32,
    num_gpus_per_worker=0.25,
))

# Run the pipeline (uses XennaExecutor by default)
results = pipeline.run()

```
:::

::::

## Key Parameters

| Parameter                    | Default | Description                                                                 |
|------------------------------|---------|-----------------------------------------------------------------------------|
| `model_dir`                  | None    | Path to directory containing model weights                                  |
| `score_threshold`            | 0.5     | NSFW score threshold for filtering (images above this are filtered out)    |
| `model_inference_batch_size` | 32      | Batch size for model inference                                              |
| `num_gpus_per_worker`        | 0.25    | GPU allocation per worker (0.25 = 1/4 GPU)                                 |
| `verbose`                    | False   | Enable verbose logging for debugging                                        |

## Performance Notes

- The model is small and can be loaded onto the GPU with the embedding model for fast, in-place scoring.
- Batch size can be increased for faster throughput if memory allows.

## Best Practices

- Use CLIP ViT-L/14 embeddings generated by `ImageEmbeddingStage` for best results.
- Run the NSFW filter immediately after embedding generation in the same pipeline to avoid extra I/O.
- Review a sample of scores to calibrate thresholds for your use case.
- Adjust `model_inference_batch_size` based on available GPU memory.

## Additional Resources

- [Image Curation Tutorial](https://github.com/NVIDIA/NeMo-Curator/blob/main/tutorials/image/getting-started/image_curation_example.py)
- [Complete Pipeline Example](https://github.com/NVIDIA/NeMo-Curator/blob/main/tutorials/image/getting-started/image_curation_example.py)