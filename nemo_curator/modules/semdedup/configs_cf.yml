root: '/raid/fayw/semdedup'
sample: 5
id_col:
   name: 'id' #'adlr_id'
   type:  int' #'str'


# Embeddings
embeddings:
  input_column: 'text'
  datapath: 'datasets/c4/realnewslike/modified/'
  #datapath: 'datasets/prospector-lm/cleaned_exact_dedup_all_cc'
  emb_parquet_path: "emb_sentmpnet_c4_crossfit_5" #"emb_fbopt125_cc_crossfit_5_v2" #
  model_name: 'facebook/opt-125m' #'sentence-transformers/all-mpnet-base-v2' # '/raid/fayw/semdedup/models/facebook-opt-125m/' 'sentence-transformers/all-mpnet-base-v2'

  emb_size: 768
  batch_size: 16
  num_workers: 4
  pool_size: '10GB'

clustering:
  save_loc: "results_fbopt125_cc_crossfit_5"
  num_clusters: 1000 # -- number of clusters
  seed: 1234
  niter: 1000
  Kmeans_with_cos_dist: True


semdedup:
  # -- which example to keep from each group of duplicates
  which_to_keep: "hard"
  # largest cluster size the memory is large enough to process. If the
  # cluster size is larger than it, we will devide the cluster into small
  # clusters and process each one separately.
  largest_cluster_size_to_process: 100000
  sim_metric: 'cosine'
  keep_hard: True # True for hard examples

extract_dedup:
  eps:  '0.01' # '0.01', '0.001', '0.0001', '1e-05', '1e-06'

