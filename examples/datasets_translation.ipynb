{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8d1a83",
   "metadata": {},
   "source": [
    "# Dataset Translation Example (using HuggingFace Datasets as a template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d96ca7",
   "metadata": {},
   "source": [
    "## Initial TranslationDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Import BaseSettings from pydantic for configuration management\n",
    "from pydantic.v1 import BaseSettings\n",
    "\n",
    "# (Optional) Define a Settings class to store model and API configuration\n",
    "class Settings(BaseSettings):\n",
    "    hf_token: str = None                        # (Change this) HuggingFace token for authentication\n",
    "    hf_model: str = \"openai/gpt-oss-20b\"        # (Change this) HuggingFace model for tokenization\n",
    "    model_name: str = \"gpt-oss:latest\"          # (Change this) Local model name\n",
    "    base_url: str = \"http://localhost:11434/v1\" # (Change this) Base URL for local API (P.S: Ollama supports the OpenAI API format.)\n",
    "\n",
    "# Instantiate the Settings object to access configuration\n",
    "setting = Settings()\n",
    "\n",
    "# Import the TranslationDataGenerator for synthetic translation tasks\n",
    "from nemo_curator.synthetic.translate import TranslationDataGenerator\n",
    "\n",
    "# Create a TranslationDataGenerator instance with specified parameters\n",
    "generator = TranslationDataGenerator(\n",
    "    base_url=setting.base_url,                              # API endpoint\n",
    "    api_key=\"\",                                             # API key (empty if not required)\n",
    "    init_translate_model=setting.model_name,                # Initial translation model\n",
    "    reflection_model=setting.model_name,                    # Reflection model for improvement\n",
    "    improvement_model=setting.model_name,                   # Model for translation improvement\n",
    "    hf_tokenizer=setting.hf_model,                          # Tokenizer model from HuggingFace\n",
    "    hf_token=setting.hf_token if setting.hf_token != \"\" else None, # HuggingFace authentication token\n",
    "    temperature=1.0,                                        # Sampling temperature for generation\n",
    "    top_p=1.0,                                              # Nucleus sampling parameter\n",
    "    max_tokens=24576,                                        # Maximum tokens for input\n",
    "    stop=[\"<|return|>\",\"<|endoftext|>\", \"<|call|>\"],        # Stop TOKEN sequences\n",
    "    max_token_per_chunk=5000,                               # Max tokens per chunk for translation\n",
    "    source_lang=\"English\",                                  # Source language\n",
    "    target_lang=\"Traditional Chinese\",                      # Target language\n",
    "    country=\"Taiwan\",                                       # (Optional) Country context for translation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03163ec1",
   "metadata": {},
   "source": [
    "## Load & Translate Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50379d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 1/1...\n",
      "EXTRACTED: 3. (6 分) 一家建設公司正在建造隧道。當隧道完成了三分之一時，他們開始使用新設備，該設備將施工速度提升 20%，並將工作時間削減至原來的 80%。最終完成隧道共花費 185 天。若不使用新設備，繼續以原速施工，完成隧道仍需 ______ 天。\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for data processing and translation\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load the Sample Dataset from HuggingFace using the provided token\n",
    "ds = load_dataset(\"TsukiOwO/Translation-Sample-Dataset\", \"default\", token=setting.hf_token if setting.hf_token != \"\" else None)[\"train\"]\n",
    "messages_zh_all = []    # List to store translated message sets\n",
    "max_examples = 1        # (Optional) Limit the number of examples processed\n",
    "\n",
    "# Iterate through filtered examples and translate messages\n",
    "for idx, example in enumerate(ds):\n",
    "    # (Optional) Set a Limit for example\n",
    "    if idx >= max_examples:\n",
    "        break\n",
    "    \n",
    "    print(f\"Processing example {idx + 1}/{max_examples}...\") \n",
    "\n",
    "    messages = example['messages']  # Get the list of messages for the example\n",
    "    messages_zh = []  # List to store translated messages for this example\n",
    "\n",
    "    for msg in messages:\n",
    "        role = msg.get('role')  # Get the role (user or assistant)\n",
    "        content = msg.get('content', '')  # Get the message content\n",
    "\n",
    "        if role == 'user':\n",
    "            # Translate user message content\n",
    "            translations = generator.generate(content, debug=True) # (Optional) debug=True: Can get the `extract_content` step information \n",
    "            translated = generator.parse_response(translations)\n",
    "            messages_zh.append({\"role\": role, \"content\": translated})\n",
    "\n",
    "        elif role == 'assistant':\n",
    "            # Extract and translate <think> content if present\n",
    "            think_match = re.search(r\"<think>(.*?)</think>\", content, re.DOTALL)\n",
    "            if think_match:\n",
    "                think_text = think_match.group(1).strip()\n",
    "                translations = generator.generate(think_text)\n",
    "                think_translated = generator.parse_response(translations)\n",
    "            else:\n",
    "                think_translated = \"\"\n",
    "            \n",
    "            # Extract and translate non-<think> content\n",
    "            result_text = re.sub(r\"<think>.*?</think>\", \"\", content, flags=re.DOTALL).strip()\n",
    "            translations = generator.generate(result_text)\n",
    "            result_translated = generator.parse_response(translations)\n",
    "            # Merge translated <think> and non-<think> content\n",
    "            combined_content = f\"<think>\\n{think_translated}</think>\\n\\n{result_translated}\"\n",
    "            messages_zh.append({\"role\": \"assistant\", \"content\": combined_content})\n",
    "            messages_zh_all.append(messages_zh)  # Add translated messages for this example\n",
    "\n",
    "# Create a DataFrame to store all translated message sets\n",
    "df = pd.DataFrame()\n",
    "df['messages_zh'] = messages_zh_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcbcce",
   "metadata": {},
   "source": [
    "## Show The Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031e50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"3. (6 分) 一家建設公司正在建造隧道。當隧道完成了三分之一時，他們開始使用新設備，該設備將施工速度提升 20%，並將工作時間削減至原來的 80%。最終完成隧道共花費 185 天。若不使用新設備，繼續以原速施工，完成隧道仍需 ______ 天。\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"<think>\\n先來分析這個問題。\\n\\n一家建設公司正在建造一條隧道。完成隧道的三分之一後，他們改用新設備。該設備使施工速度提高 20%，但每日工作時數被削減至原來的 80%。使用新設備後，總共耗時 185 天。請問若不使用新設備，改以原始速度繼續建造，總共會耗時多少天？\\n\\n設全長為 1 個隧道。  \\n原始施工速率為 \\\\(R\\\\)（隧道/天），若不變則需完成整條隧道的時間為  \\n\\\\[\\nT=\\\\frac{1}{R}\\\\quad(\\\\text{天}) .\\n\\\\]\\n\\n**第一階段**  \\n以原速率完成三分之一，所需時間  \\n\\\\[\\nt_1=\\\\frac{\\\\tfrac13}{R}=\\\\frac{1}{3R}\\\\quad(\\\\text{天}) .\\n\\\\]\\n\\n**第二階段**  \\n剩餘三分之二按新設備施工。新設備使速率提升 20%，即從 \\\\(R\\\\) 變為 \\\\(1.2R\\\\)。  \\n原本每日工作 \\\\(H\\\\) 小時，提升後速率為每小時 \\\\(\\\\tfrac{R}{H}\\\\)。提高 20% 之後為 \\\\(1.2\\\\tfrac{R}{H}\\\\)。  \\n但每日工作時數下降至 \\\\(0.8H\\\\)，因此每日新速率為  \\n\\\\[\\n1.2\\\\tfrac{R}{H}\\\\times 0.8H = 0.96R \\\\quad(\\\\text{隧道/天}) .\\n\\\\]\\n此階段所需時間  \\n\\\\[\\nt_2=\\\\frac{\\\\tfrac23}{0.96R}\\\\quad(\\\\text{天}) .\\n\\\\]\\n\\n已知總時間為 185 天，所以  \\n\\\\[\\nt_1+t_2 = \\\\frac{1}{3R}+\\\\frac{\\\\tfrac23}{0.96R}=185 .\\n\\\\]\\n\\n化簡分子：  \\n\\\\[\\n\\\\frac13+\\\\frac{\\\\tfrac23}{0.96}\\n=\\\\frac13+\\\\frac{\\\\tfrac23\\\\times\\\\frac{25}{24}}\\n=\\\\frac13+\\\\frac{25}{36}\\n=\\\\frac{12}{36}+\\\\frac{25}{36}\\n=\\\\frac{37}{36}.\\n\\\\]\\n\\n因此  \\n\\\\[\\n\\\\frac{37}{36}\\\\cdot\\\\frac{1}{R}=185\\n\\\\;\\\\Longrightarrow\\\\;\\nR=\\\\frac{37}{36\\\\times185}=\\\\frac{1}{180}\\\\quad(\\\\text{隧道/天}) .\\n\\\\]\\n\\n原始總時間  \\n\\\\[\\nT=\\\\frac{1}{R}=180\\\\quad(\\\\text{天}) .\\n\\\\]\\n\\n驗算：  \\n- 第一階段時間：\\\\(\\\\frac{1}{3}\\\\div\\\\frac{1}{180}=60\\\\) 天。  \\n- 第二階段時間：\\\\(\\\\frac{2}{3}\\\\div0.96\\\\cdot\\\\frac{1}{180}=125\\\\) 天。  \\n兩階段相加 \\\\(60+125=185\\\\) 天，符合已知總時間。\\n\\n**答案**  \\n若不使用新設備，整條隧道將會在 180 天內完成。  \\n\\\\boxed{180\\\\text{ 天}}</think>\\n\\n讓 \\\\(T\\\\) 為完成本隧道所需的原始日數。原始施工速率為 \\\\( \\\\frac{1}{T} \\\\) 隧道/日。當本隧道完成三分之一時，使用原始速率所耗時間為：\\\\(\\\\frac{T}{3}\\\\) 日。\\n\\n剩餘三分之二的隧道，施工速率提高了 20%，每日工作時間縮減至原來的 80%。新的施工速率為 \\\\(1.2 \\\\times \\\\frac{1}{T}\\\\) 隧道/小時，但由於工作時間減少，實際有效每日施工進度為：\\\\(1.2 \\\\times \\\\frac{1}{T} \\\\times 0.8 = \\\\frac{0.96}{T}\\\\) 隧道/日。\\n\\n按照新的速率完成剩餘三分之二的隧道所需時間為：\\\\(\\\\frac{2/3}{0.96/T} = \\\\frac{2T}{3 \\\\times 0.96} = \\\\frac{2T}{2.88} = \\\\frac{25T}{36}\\\\) 日。\\n\\n總用 185 日完成本隧道的時間為：\\\\(\\\\frac{T}{3} + \\\\frac{25T}{36} = 185\\\\)。\\n\\n將項合併：\\\\(\\\\frac{12T}{36} + \\\\frac{25T}{36} = \\\\frac{37T}{36} = 185\\\\)。\\n\\n求得 \\\\(T\\\\)：\\\\(T = 185 \\\\times \\\\frac{36}{37} = 180\\\\)。\\n\\n則若未使用新設備並沿原始速率施工，完成本隧道將需要 \\\\(\\\\boxed{180}\\\\) 日。\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Print the translated messages for the first example in formatted JSON\n",
    "print(json.dumps(df['messages_zh'].iloc[0], ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
