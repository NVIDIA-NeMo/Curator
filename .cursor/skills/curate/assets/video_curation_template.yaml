# Video Curation Pipeline Template
# Generated by CURATOR-OS
#
# This template provides a video curation workflow with:
# - Video reading
# - Scene detection (TransNetV2)
# - Motion filtering
# - Optional captioning
# - Optional embedding generation
#
# Usage:
#   python -m nemo_curator.config.run --config-path=. --config-name=video_curation_template \
#     input_path=/data/videos output_path=/data/clips

defaults:
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

hydra:
  run:
    dir: .
  output_subdir: null

# Configuration (override on command line)
input_path: ???  # Required: path to input videos
output_path: ???  # Required: path for output clips

# Ray Client Configuration
ray_client:
  _target_: nemo_curator.core.client.RayClient
  num_cpus: null  # Use all available
  num_gpus: 4

# Pipeline Stages
stages:

  # ========================================
  # Stage 1: Read Videos
  # ========================================
  - _target_: nemo_curator.stages.video.io.video_reader.VideoReader
    input_path: ${input_path}

  # ========================================
  # Stage 2: Scene Detection / Clipping
  # ========================================
  
  # Option A: ML-based scene detection (GPU, ~16GB)
  - _target_: nemo_curator.stages.video.clipping.TransNetV2ClipExtractionStage
    # GPU memory: ~16GB
    # Detects scene boundaries using ML model

  # Option B: Fixed-duration clips (CPU)
  # Uncomment to use instead of TransNetV2
  # - _target_: nemo_curator.stages.video.clipping.FixedStrideExtractorStage
  #   clip_duration: 10.0  # seconds
  #   stride: 10.0  # seconds (non-overlapping)

  # ========================================
  # Stage 3: Motion Filtering (Optional)
  # ========================================
  # Remove static or low-motion clips
  
  - _target_: nemo_curator.stages.video.filtering.MotionVectorDecodeStage
    # Decodes motion vectors from video (CPU)

  - _target_: nemo_curator.stages.video.filtering.MotionFilterStage
    min_motion_threshold: 0.1
    # Filters out clips with motion below threshold

  # ========================================
  # Stage 4: Captioning (Optional)
  # ========================================
  # Uncomment to generate video captions
  # Requires: 1 GPU with ~24GB memory

  # - _target_: nemo_curator.stages.video.caption.CaptionPreparationStage
  #   # Prepares video windows for caption model

  # - _target_: nemo_curator.stages.video.caption.CaptionGenerationStage
  #   # Generates captions using Qwen VL
  #   # GPU: 1 full GPU (~24GB)

  # - _target_: nemo_curator.stages.video.caption.CaptionEnhancementStage
  #   # Optional: Refine captions with Qwen LM

  # ========================================
  # Stage 5: Embedding Generation (Optional)
  # ========================================
  # Uncomment to generate video embeddings
  
  # Option A: NVIDIA Cosmos Embed1 (recommended)
  # - _target_: nemo_curator.stages.video.embedding.CosmosEmbed1FrameCreationStage
  #   # Prepares frames for embedding

  # - _target_: nemo_curator.stages.video.embedding.CosmosEmbed1EmbeddingStage
  #   # GPU memory: ~16GB
  #   # Supports 224p, 336p, 448p resolutions

  # Option B: InternVideo2
  # - _target_: nemo_curator.stages.video.embedding.InternVideo2EmbeddingStage
  #   # Alternative embedding model

  # ========================================
  # Stage 6: Aesthetic Filtering (Optional)
  # ========================================
  # Uncomment to filter by visual quality
  
  # - _target_: nemo_curator.stages.video.filtering.ClipAestheticFilterStage
  #   min_aesthetic_score: 0.5

  # ========================================
  # Stage 7: Write Clips
  # ========================================
  - _target_: nemo_curator.stages.video.io.ClipWriterStage
    output_path: ${output_path}
