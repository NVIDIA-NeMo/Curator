# Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Generate NeMo Curator video pipeline YAML configuration.

Examples:
    # Basic clip extraction
    python generate_video_config.py \\
        --input-path /data/videos \\
        --output-path /data/clips \\
        --output-file video_pipeline.yaml

    # Full pipeline with captioning
    python generate_video_config.py \\
        --input-path /data/videos \\
        --output-path /data/clips \\
        --clip-method transnetv2 \\
        --caption \\
        --embed \\
        --output-file full_pipeline.yaml
"""
import argparse
import sys
from pathlib import Path


def generate_video_yaml(args: argparse.Namespace) -> str:
    """Generate Hydra-compatible YAML for video processing."""
    lines = []

    # Header
    lines.append("# Video Curation Pipeline")
    lines.append("# Generated by NeMo Curator video skill")
    lines.append("#")
    lines.append(f"# Input: {args.input_path}")
    lines.append(f"# Output: {args.output_path}")
    lines.append(f"# Clipping: {args.clip_method}")
    lines.append(f"# Captioning: {'enabled' if args.caption else 'disabled'}")
    lines.append(f"# Embedding: {'enabled' if args.embed else 'disabled'}")
    lines.append("")
    lines.append("defaults:")
    lines.append("  - _self_")
    lines.append("  - override hydra/job_logging: none")
    lines.append("  - override hydra/hydra_logging: none")
    lines.append("")
    lines.append("hydra:")
    lines.append("  run:")
    lines.append("    dir: .")
    lines.append("  output_subdir: null")
    lines.append("")

    # Configuration variables
    lines.append("# Configuration (override on command line)")
    lines.append(f"input_path: {args.input_path}")
    lines.append(f"output_path: {args.output_path}")
    if args.model_dir:
        lines.append(f"model_dir: {args.model_dir}")
    else:
        lines.append("model_dir: ./models")
    lines.append("")

    # Stages
    lines.append("stages:")
    lines.append("")

    # Stage 1: Video Reader
    lines.append("  # ========================================")
    lines.append("  # Stage 1: Read Videos")
    lines.append("  # ========================================")
    lines.append("  - _target_: nemo_curator.stages.video.io.video_reader.VideoReader")
    lines.append("    input_video_path: ${input_path}")
    if args.video_limit:
        lines.append(f"    video_limit: {args.video_limit}")
    lines.append("")

    # Stage 2: Clipping
    lines.append("  # ========================================")
    lines.append("  # Stage 2: Scene Detection / Clipping")
    lines.append("  # ========================================")

    if args.clip_method == "transnetv2":
        lines.append("  # Frame extraction for TransNetV2")
        lines.append("  - _target_: nemo_curator.stages.video.clipping.video_frame_extraction.VideoFrameExtractionStage")
        lines.append(f"    decoder_mode: {args.transnetv2_decoder}")
        lines.append("")
        lines.append("  # TransNetV2 scene detection")
        lines.append("  - _target_: nemo_curator.stages.video.clipping.transnetv2_extraction.TransNetV2ClipExtractionStage")
        lines.append("    model_dir: ${model_dir}")
        lines.append(f"    threshold: {args.transnetv2_threshold}")
        lines.append(f"    min_length_s: {args.transnetv2_min_length}")
        lines.append(f"    max_length_s: {args.transnetv2_max_length}")
        lines.append(f"    gpu_memory_gb: {args.transnetv2_gpu_memory}")
    else:
        lines.append("  # Fixed stride clipping")
        lines.append("  - _target_: nemo_curator.stages.video.clipping.clip_extraction_stages.FixedStrideExtractorStage")
        lines.append(f"    clip_len_s: {args.fixed_stride_duration}")
        lines.append(f"    clip_stride_s: {args.fixed_stride_duration}")
        lines.append(f"    min_clip_length_s: {args.fixed_stride_min_length}")
        lines.append("    limit_clips: -1")

    lines.append("")

    # Stage 3: Transcoding
    lines.append("  # ========================================")
    lines.append("  # Stage 3: Clip Transcoding")
    lines.append("  # ========================================")
    lines.append("  - _target_: nemo_curator.stages.video.clipping.clip_extraction_stages.ClipTranscodingStage")
    lines.append(f"    encoder: {args.encoder}")
    lines.append(f"    num_cpus_per_worker: {args.transcode_cpus}")
    lines.append("")

    # Stage 4: Motion Filtering (optional)
    if args.filter_motion:
        lines.append("  # ========================================")
        lines.append("  # Stage 4: Motion Filtering")
        lines.append("  # ========================================")
        lines.append("  - _target_: nemo_curator.stages.video.filtering.motion_filter.MotionVectorDecodeStage")
        lines.append("    target_fps: 2.0")
        lines.append("    target_duration_ratio: 0.5")
        lines.append("")
        lines.append("  - _target_: nemo_curator.stages.video.filtering.motion_filter.MotionFilterStage")
        lines.append(f"    global_mean_threshold: {args.motion_threshold}")
        lines.append("    score_only: false")
        lines.append("")

    # Stage 5: Aesthetic Filtering (optional)
    if args.aesthetic_threshold:
        lines.append("  # ========================================")
        lines.append("  # Stage 5: Aesthetic Filtering")
        lines.append("  # ========================================")
        lines.append("  - _target_: nemo_curator.stages.video.clipping.clip_frame_extraction.ClipFrameExtractionStage")
        lines.append("")
        lines.append("  - _target_: nemo_curator.stages.video.filtering.clip_aesthetic_filter.ClipAestheticFilterStage")
        lines.append("    model_dir: ${model_dir}")
        lines.append(f"    score_threshold: {args.aesthetic_threshold}")
        lines.append("")

    # Stage 6: Captioning (optional)
    if args.caption:
        lines.append("  # ========================================")
        lines.append("  # Stage 6: Video Captioning")
        lines.append("  # ========================================")
        lines.append("  - _target_: nemo_curator.stages.video.caption.caption_preparation.CaptionPreparationStage")
        lines.append(f"    model_variant: {args.caption_model}")
        lines.append(f"    sampling_fps: {args.caption_fps}")
        lines.append("")
        lines.append("  - _target_: nemo_curator.stages.video.caption.caption_generation.CaptionGenerationStage")
        lines.append("    model_dir: ${model_dir}")
        lines.append(f"    model_variant: {args.caption_model}")
        lines.append(f"    caption_batch_size: {args.caption_batch_size}")
        lines.append("")

        if args.enhance_captions:
            lines.append("  # Caption enhancement")
            lines.append("  - _target_: nemo_curator.stages.video.caption.caption_enhancement.CaptionEnhancementStage")
            lines.append("    model_dir: ${model_dir}")
            lines.append("")

    # Stage 7: Embedding (optional)
    if args.embed:
        lines.append("  # ========================================")
        lines.append("  # Stage 7: Video Embedding")
        lines.append("  # ========================================")
        lines.append("  # Frame extraction required before embedding")
        lines.append("  - _target_: nemo_curator.stages.video.clipping.clip_frame_extraction.ClipFrameExtractionStage")
        lines.append("    target_fps:")
        lines.append("      - 2.0")
        lines.append("")

        if args.embed_model.startswith("cosmos"):
            variant = args.embed_model.split("-")[-1]
            lines.append("  - _target_: nemo_curator.stages.video.embedding.cosmos_embed1.CosmosEmbed1FrameCreationStage")
            lines.append("    model_dir: ${model_dir}")
            lines.append(f"    variant: {variant}")
            lines.append("    target_fps: 2.0")
            lines.append("")
            lines.append("  - _target_: nemo_curator.stages.video.embedding.cosmos_embed1.CosmosEmbed1EmbeddingStage")
            lines.append("    model_dir: ${model_dir}")
            lines.append(f"    variant: {variant}")
            lines.append(f"    gpu_memory_gb: {args.embed_gpu_memory}")
        else:
            lines.append("  - _target_: nemo_curator.stages.video.embedding.internvideo2.InternVideo2FrameCreationStage")
            lines.append("    model_dir: ${model_dir}")
            lines.append("    target_fps: 2.0")
            lines.append("")
            lines.append("  - _target_: nemo_curator.stages.video.embedding.internvideo2.InternVideo2EmbeddingStage")
            lines.append("    model_dir: ${model_dir}")
            lines.append(f"    gpu_memory_gb: {args.embed_gpu_memory}")

        lines.append("")

    # Stage 8: Write clips
    lines.append("  # ========================================")
    lines.append("  # Stage 8: Write Clips")
    lines.append("  # ========================================")
    lines.append("  - _target_: nemo_curator.stages.video.io.clip_writer.ClipWriterStage")
    lines.append("    output_path: ${output_path}")
    lines.append("    input_path: ${input_path}")
    lines.append(f"    generate_embeddings: {str(args.embed).lower()}")
    lines.append(f"    generate_captions: {str(args.caption).lower()}")
    lines.append(f"    generate_previews: {str(args.caption).lower()}")
    lines.append("    upload_clips: true")
    lines.append("    dry_run: false")
    if args.embed:
        if args.embed_model.startswith("cosmos"):
            lines.append("    embedding_algorithm: cosmos-embed1")
        else:
            lines.append("    embedding_algorithm: internvideo2")
    if args.caption:
        lines.append("    caption_models:")
        lines.append(f"      - {args.caption_model}")
        lines.append("    enhanced_caption_models: []")

    return "\n".join(lines)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Generate NeMo Curator video pipeline configuration"
    )

    # Required arguments
    parser.add_argument(
        "--input-path", "-i", required=True, help="Path to input videos"
    )
    parser.add_argument(
        "--output-path", "-o", required=True, help="Path for output clips"
    )
    parser.add_argument(
        "--output-file", "-f", default="video_pipeline.yaml", help="Output YAML file"
    )

    # General options
    parser.add_argument(
        "--model-dir", help="Path to model directory"
    )
    parser.add_argument(
        "--video-limit", type=int, help="Limit number of videos to process"
    )

    # Clipping options
    parser.add_argument(
        "--clip-method",
        choices=["transnetv2", "fixed_stride"],
        default="transnetv2",
        help="Clipping method",
    )

    # TransNetV2 options
    parser.add_argument(
        "--transnetv2-threshold", type=float, default=0.4, help="Scene detection threshold"
    )
    parser.add_argument(
        "--transnetv2-min-length", type=float, default=2.0, help="Minimum clip length (seconds)"
    )
    parser.add_argument(
        "--transnetv2-max-length", type=float, default=10.0, help="Maximum clip length (seconds)"
    )
    parser.add_argument(
        "--transnetv2-gpu-memory", type=float, default=10.0, help="GPU memory for TransNetV2"
    )
    parser.add_argument(
        "--transnetv2-decoder",
        choices=["pynvc", "ffmpeg_gpu", "ffmpeg_cpu"],
        default="pynvc",
        help="Video decoder mode",
    )

    # Fixed stride options
    parser.add_argument(
        "--fixed-stride-duration", type=float, default=10.0, help="Clip duration (seconds)"
    )
    parser.add_argument(
        "--fixed-stride-min-length", type=float, default=2.0, help="Minimum clip length"
    )

    # Transcoding options
    parser.add_argument(
        "--encoder",
        choices=["libopenh264", "h264_nvenc", "libx264"],
        default="libopenh264",
        help="Video encoder",
    )
    parser.add_argument(
        "--transcode-cpus", type=float, default=6.0, help="CPUs per transcoding worker"
    )

    # Filtering options
    parser.add_argument(
        "--filter-motion", action="store_true", default=True, help="Enable motion filtering"
    )
    parser.add_argument(
        "--no-filter-motion", action="store_false", dest="filter_motion"
    )
    parser.add_argument(
        "--motion-threshold", type=float, default=0.00098, help="Motion threshold"
    )
    parser.add_argument(
        "--aesthetic-threshold", type=float, help="Aesthetic score threshold"
    )

    # Captioning options
    parser.add_argument(
        "--caption", action="store_true", help="Enable captioning"
    )
    parser.add_argument(
        "--caption-model", default="qwen", help="Caption model variant"
    )
    parser.add_argument(
        "--caption-fps", type=float, default=2.0, help="Caption sampling FPS"
    )
    parser.add_argument(
        "--caption-batch-size", type=int, default=8, help="Caption batch size"
    )
    parser.add_argument(
        "--enhance-captions", action="store_true", help="Enable caption enhancement"
    )

    # Embedding options
    parser.add_argument(
        "--embed", action="store_true", default=True, help="Enable embedding"
    )
    parser.add_argument(
        "--no-embed", action="store_false", dest="embed"
    )
    parser.add_argument(
        "--embed-model",
        default="cosmos-embed1-224p",
        choices=["cosmos-embed1-224p", "cosmos-embed1-336p", "cosmos-embed1-448p", "internvideo2"],
        help="Embedding model",
    )
    parser.add_argument(
        "--embed-gpu-memory", type=float, default=20.0, help="GPU memory for embedding"
    )

    args = parser.parse_args()

    # Generate YAML
    yaml_content = generate_video_yaml(args)

    # Write to file
    output_path = Path(args.output_file)
    output_path.write_text(yaml_content)

    print(f"Generated video pipeline configuration: {output_path}")
    print()
    print("To run the pipeline:")
    print(f"  python -m nemo_curator.config.run --config-path=. --config-name={output_path.stem}")


if __name__ == "__main__":
    main()
